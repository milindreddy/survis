@inproceedings{Nair2018VisualRL,
  type         = {inproceedings},
  author       = {Ashvin Nair and Vu Pong and Murtaza Dalal and Abhishek Srinivas and et al.},
  title        = {Visual Reinforcement Learning with Imagined Goals},
  booktitle    = {Advances in {Neural} {Information} {Processing} {Systems} (NeurIPS)},
  volume       = {31},
  year         = {2018},
  doi          = {10.48550/arXiv.1807.04742},
  url          = {https://arxiv.org/pdf/1807.04742},
  keywords     = {type:visual-rl, goal-sampling, {VAE}, latent-space}
  type         = {visual-rl}
}

@inproceedings{Mu2022CtrlFormer,
  type         = {inproceedings},
  author       = {Jun Mu and Nikolay Savinov and Tianhe Shen and Xiaowei Zhou and et al.},
  title        = {CtrlFormer: Learning Transferable State Representation for Visual Control via Transformer},
  booktitle    = {Proceedings of the 39th International Conference on {Machine} {Learning} (ICML)},
  series       = {PMLR},
  volume       = {162},
  year         = {2022},
  doi          = {10.48550/arXiv.2206.08883},
  url          = {https://arxiv.org/pdf/2206.08883},
  keywords     = {type:transformer, visual-control, transfer-learning, self-attention}
  type         = {transformer}
}

@inproceedings{Choi2023LocalGuidedGlobal,
  type         = {inproceedings},
  author       = {Soo Hyun Choi and Jiyoung Lee and Hyunsoo Kim and et al.},
  title        = {Local-Guided Global: Paired Similarity Representation for Visual Reinforcement Learning},
  booktitle    = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages        = {1447--1456},
  year         = {2023},
  doi          = {10.1109/CVPR52729.2023.01447},
  url          = {https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10204973},
  keywords     = {type:correspondence, pixel-wise, representation-learning, PSRL}
  type         = {correspondence}
}

@inproceedings{Kich2024CurledDreamer,
  type         = {inproceedings},
  author       = {Daniel Kich and Li Zhang and Peng Wang and et al.},
  title        = {{CURLing} the {Dream}: Contrastive Representations for World Modeling in RL},
  booktitle    = {Proceedings of the International Conference on Control, Automation and Systems (ICCAS)},
  pages        = {730--738},
  year         = {2024},
  doi          = {10.23919/ICCAS63016.2024.10773008},
  url          = {https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10773008},
  keywords     = {type:contrastive, reconstruction, world-modeling, Dreamer}
  type         = {contrastive}
}

@article{Uzkent2020WhenWhereZoom,
  type         = {article},
  author       = {Burak Uzkent and Stefano Ermon},
  title        = {Learning When and Where to Zoom with Deep Reinforcement Learning},
  journal      = {arXiv Preprint arXiv:2003.00425},
  year         = {2020},
  doi          = {10.48550/arXiv.2003.00425},
  url          = {https://arxiv.org/pdf/2003.00425},
  keywords     = {type:dynamic-dropping, patch-drop, robustness, large-image}
  type         = {dynamic-dropping}
}

@article{Uzkent2020EfficientDetection,
  type         = {article},
  author       = {Burak Uzkent and Stefano Ermon and et al.},
  title        = {Efficient Object Detection in Large Images using Deep RL},
  journal      = {arXiv Preprint arXiv:1912.03966},
  year         = {2020},
  doi          = {10.48550/arXiv.1912.03966},
  url          = {https://arxiv.org/pdf/1912.03966},
  keywords     = {type:cascade, patch-selection, large-images, FPNet}
  type         = {cascade}
}

@article{Wu2025DNRSelect,
  type         = {article},
  author       = {Ying Wu and Jun Zhao and Weichao Li and et al.},
  title        = {DNRSelect: Active Best View Selection for Deferred Neural Rendering},
  journal      = {arXiv Preprint arXiv:2501.12150},
  year         = {2025},
  doi          = {10.48550/arXiv.2501.12150},
  url          = {https://arxiv.org/pdf/2501.12150},
  keywords     = {type:view-selection, novel-view, active, information-gain}
  type         = {view-selection}
}

@inproceedings{Lee2024RLExposure,
  type         = {inproceedings},
  author       = {Minjoon Lee and Seungjae Kim and Taeil Park and et al.},
  title        = {Learning to Control Camera Exposure via RL},
  booktitle    = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year         = {2024},
  doi          = {10.48550/arXiv.2404.01636},
  url          = {https://arxiv.org/pdf/2404.01636},
  keywords     = {type:exposure-control, camera-AE, real-time, deep-RL}
  type         = {exposure-control}
}

@inproceedings{Park2018DistortRecover,
  type         = {inproceedings},
  author       = {Keunwoo Park and Donggeun Kim and et al.},
  title        = {Distort-and-Recover: Color Enhancement using DRL},
  booktitle    = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages        = {456--464},
  year         = {2018},
  doi          = {10.1109/CVPR.2018.00621},
  url          = {https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8578719},
  keywords     = {type:image-enhancement, deep-RL, interpretable, editing-sequence}
  type         = {image-enhancement}
}

@article{Chen2024STARRL,
  type         = {article},
  author       = {Li Chen and Hao Zhang and Ming Xu and et al.},
  title        = {STAR-RL: Hierarchical RL for Pathology Image Super-Resolution},
  journal      = {IEEE Transactions on Medical Imaging},
  volume       = {43},
  number       = {7},
  pages        = {2301--2313},
  year         = {2024},
  doi          = {10.1109/TMI.2024.3419809},
  url          = {https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10574839},
  keywords     = {type:hierarchical-rl, spatial-temporal, pathology, patch-worker}
  type         = {hierarchical-rl}
}
